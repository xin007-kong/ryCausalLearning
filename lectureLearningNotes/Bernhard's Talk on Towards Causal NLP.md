**Bernhard's Talk on Towards Causal NLP ç¬”è®°**

> å› æžœå­¦ä¹ ç³»åˆ—ç¬”è®°

> è¿™æ˜¯æˆ‘çš„ GitHub å› æžœå­¦ä¹ ç¬”è®°ä»“åº“
> [https://github.com/xin007-kong/ryCausalLearning]()ï¼Œæ¬¢è¿Ž starðŸ¤©

- è®²è€…æ˜¯ Bernhard SchÃ¶lkopf
  - talk é“¾æŽ¥ï¼š[(41) Bernhard Schoelkopf | Towards Causal NLP | Keynote@EMNLP 2021 Causal Inference and NLP Workshop - YouTube](https://www.youtube.com/watch?v=Zwt1jJxVSvg&list=PLtVBX_ld338UTeq9LphgjCfMpM2EcSbEs&index=3)
  - è°·æ­Œå­¦æœ¯ä¸»é¡µï¼š[â€ªBernhard SchÃ¶lkopfâ€¬ - â€ªGoogle Scholarâ€¬](https://scholar.google.com/citations?user=DZ-fHPgAAAAJ&hl=en)
- æ¦‚æ‹¬ä¸€ä¸‹ talk çš„å†…å®¹
- Machine learning relies on correlations rather than causality, which can lead to limitations in object recognition and adversarial vulnerability.
- Causal inference connects correlation and causality, suggesting that statistically dependent variables have a causal explanation.

* Structural causal models provide a formalism for thinking about causality, using directed acyclic graphs (DAGs) to represent causal relationships.
* Causal factorization allows the joint distribution to be expressed as a product of conditionals, reducing the dimensionality of the variables.
* The goal is to move towards causal representation learning, combining interventional knowledge and learned representations for richer and more data-efficient world models.
